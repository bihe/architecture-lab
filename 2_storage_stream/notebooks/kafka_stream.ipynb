{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4374a3a8-9176-4206-9a43-4909402f85a1",
   "metadata": {},
   "source": [
    "## Read streaming data from a Kafka Topic\n",
    "The notebook establishes a spark-session with the local (in-memory) spark environment of the container.\n",
    "A spark master-node needs to be specified. This is done by setting `master` to `local[*]`.\n",
    "\n",
    "The provided messages from the Kafka topic are just simple text-messages, therefor this example lacks schema definition.\n",
    "\n",
    "To read from a Kafka-stream we use `spark.readStream` specifying the Kafka server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3b470-8b8a-4c06-97d0-99fa1a1f5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output, display\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaStream\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def handle_batch(df, epoch_id):\n",
    "    # Convert to Pandas for display\n",
    "    pdf = df.selectExpr(\"CAST(value AS STRING)\").toPandas()\n",
    "    #clear_output(wait=True)\n",
    "    display(pdf)\n",
    "\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"test-topic\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "query = df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .foreachBatch(handle_batch) \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97337f2-44eb-4764-be4d-7166d8fcfed4",
   "metadata": {},
   "source": [
    "## Output\n",
    "New messages will \"arrive\" when created via a Kafka producer (see the console-example).\n",
    "To stop the stream-processing tell the query it is enough>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efeaa0b-6574-4f50-898a-76eddceea763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is active:\", query.isActive)\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c5b82-ad98-4f39-aa8b-c6c2719fef43",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Finally we also stop the spark session to have a clean house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02163544-9945-42c2-9553-2c412c321066",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
